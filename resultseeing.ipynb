{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from torch_geometric.utils import to_dense_adj\n",
    "from utils.getdata import getdata\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import normalize\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataroot= os.path.join(\"data\",\"attraction\")\n",
    "clusteringresult_dir = os.path.join(\"result\", \"attraction\")\n",
    "attraction  = pd.read_csv(os.path.join(dataroot,\"legaldata.csv\"))\n",
    "name = attraction['Name'].tolist()\n",
    "toldscribe = attraction['Toldescribe'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attraction.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN looked like result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlist = torch.load(os.path.join(dataroot,\"processed\",\"order.pt\"))\n",
    "print(nlist.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seeresult(target, nblist,name, numofn=6, out=False):\n",
    "    nbi = []\n",
    "    if out:\n",
    "        print(f\"{name[target]}:\")\n",
    "    nbi.append(name[target])\n",
    "    idx = nblist[target][1:numofn].tolist()\n",
    "    for i in idx:\n",
    "        if out:\n",
    "            print(name[i])\n",
    "        nbi.append(name[i])\n",
    "    return nbi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testtexts = np.random.randint(low=0, high=len(name), size=10)\n",
    "print(testtexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in testtexts:\n",
    "    r=seeresult(i, nblist=nlist, name=name, numofn=6, out=True)\n",
    "    print(\"==============================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = []\n",
    "numofn = 5\n",
    "col = ['target']+list(str(i)+\"nn\" for i in range(numofn))\n",
    "print(col)\n",
    "for i, _ in enumerate(name):\n",
    "    nb = seeresult(target=i, nblist=nlist, name=name, numofn=6)\n",
    "    knn.append(nb)\n",
    "attractionknn = pd.DataFrame(knn,columns=col)\n",
    "attractionknn.to_csv(os.path.join(dataroot, f\"KNN_{numofn}.csv\"), index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eigen of Laplacian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mygraph = getdata(\n",
    "    datafolder=os.path.join(\"dataset\",\"attraction\",f\"K_{5}\"),\n",
    "    nor=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj = to_dense_adj(mygraph.edge_index)\n",
    "adj = adj.numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse.csgraph import laplacian\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = laplacian(adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals, vecs = np.linalg.eig(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals_sorted = np.sort(-vals)\n",
    "vals_sorted[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topN = vals_sorted.shape[0]\n",
    "topN = 15\n",
    "fig = plt.figure(figsize=(12,12))\n",
    "plt.plot(\n",
    "    list(i for i in range(topN)), \n",
    "    -vals_sorted[:topN]\n",
    ")\n",
    "\"\"\"\n",
    "for i in range(topN):\n",
    "    plt.plot(\n",
    "        [i]*math.floor(vals[i]),\n",
    "        list(j for j in range(math.floor(vals[i])))\n",
    "    )\n",
    "\"\"\"\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals[290:300]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering look like result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TSNE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "told = torch.load(os.path.join(dataroot,\"ToldescribeEBD.pt\"))\n",
    "told = told.numpy()\n",
    "tsneTold = TSNE(n_components=2, learning_rate='auto', init='pca').fit_transform(told)\n",
    "tsneTold = normalize(tsneTold, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get clustering result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_num = 6\n",
    "graph = f\"K_5\"\n",
    "clusteringresult = torch.load(os.path.join(clusteringresult_dir,f\"{graph}_{g_num}\", \"cluster.pt\"))\n",
    "clusteringresult = clusteringresult.numpy()\n",
    "clusteringresult.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check if there exists orphans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = 0\n",
    "for idx, i in enumerate(clusteringresult):\n",
    "    s = i.sum()\n",
    "    if s == 0:\n",
    "        #print(idx)\n",
    "        z += 1\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write each group to a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = {}\n",
    "for i in range(g_num):\n",
    "    clusters[i]= []\n",
    "\n",
    "for idx, i in enumerate(clusteringresult):\n",
    "    belong = np.nonzero(i)[0].tolist()\n",
    "    for groupid in belong:\n",
    "            clusters[groupid].append(idx)\n",
    "for i in range(g_num):\n",
    "    print(len(clusters[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputdir = os.path.join(clusteringresult_dir,f\"{graph}_{g_num}\",\"clustering_result\")\n",
    "if not os.path.isdir(outputdir):\n",
    "    print(outputdir)\n",
    "    os.mkdir(outputdir)\n",
    "    os.mkdir(os.path.join(outputdir,\"eachC\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=['name','description']+list(str(i) for i in range(g_num))\n",
    "attrcl = []\n",
    "for idx, attrgroup in enumerate(clusteringresult):\n",
    "    thisattr = [name[idx], toldscribe[idx]]\n",
    "    thisattr = thisattr+attrgroup.tolist()\n",
    "    attrcl.append(thisattr)\n",
    "df = pd.DataFrame(attrcl,columns=columns)\n",
    "df.to_csv(os.path.join(outputdir,\"cluster.csv\"), index=False, encoding='utf-8')\n",
    "\n",
    "for i in range(g_num):\n",
    "    ci = df[df[str(i)]==1]\n",
    "    ci.to_csv(os.path.join(outputdir,\"eachC\",f\"{g_num}-c{i}.csv\"),index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "each_g = []\n",
    "for l in tqdm(range(g_num)):\n",
    "    gi = []\n",
    "    for i in range(df.shape[0]):\n",
    "        if df.iloc[i][str(l)] == 1:\n",
    "            gi.append(tsneTold[i])\n",
    "    gj = np.array(gi)\n",
    "    each_g.append(gj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glist = list(i for i in range(g_num))\n",
    "colors = cm.rainbow(np.linspace(0, 1, len(glist)))\n",
    "plt.figure(figsize=(12,12))\n",
    "for y, c in tqdm(zip(glist, colors)):\n",
    "    this_g = each_g[y]\n",
    "    plt.scatter(this_g[:, 0], this_g[:, 1], color=c)\n",
    "plt.savefig(os.path.join(outputdir,\"vis.jpg\"))\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f7401c3a6738d15d752740af9785731698b5ffd5adfb1a735c0bc94da9902075"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
